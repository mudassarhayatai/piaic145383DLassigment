{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"ionosphere_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...    feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...     -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...     -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...     -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...      0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...     -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      "feature1     351 non-null int64\n",
      "feature2     351 non-null int64\n",
      "feature3     351 non-null float64\n",
      "feature4     351 non-null float64\n",
      "feature5     351 non-null float64\n",
      "feature6     351 non-null float64\n",
      "feature7     351 non-null float64\n",
      "feature8     351 non-null float64\n",
      "feature9     351 non-null float64\n",
      "feature10    351 non-null float64\n",
      "feature11    351 non-null float64\n",
      "feature12    351 non-null float64\n",
      "feature13    351 non-null float64\n",
      "feature14    351 non-null float64\n",
      "feature15    351 non-null float64\n",
      "feature16    351 non-null float64\n",
      "feature17    351 non-null float64\n",
      "feature18    351 non-null float64\n",
      "feature19    351 non-null float64\n",
      "feature20    351 non-null float64\n",
      "feature21    351 non-null float64\n",
      "feature22    351 non-null float64\n",
      "feature23    351 non-null float64\n",
      "feature24    351 non-null float64\n",
      "feature25    351 non-null float64\n",
      "feature26    351 non-null float64\n",
      "feature27    351 non-null float64\n",
      "feature28    351 non-null float64\n",
      "feature29    351 non-null float64\n",
      "feature30    351 non-null float64\n",
      "feature31    351 non-null float64\n",
      "feature32    351 non-null float64\n",
      "feature33    351 non-null float64\n",
      "feature34    351 non-null float64\n",
      "label        351 non-null object\n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "se = StandardScaler()\n",
    "df[[\"feature1\",\"feature2\"]] = se.fit_transform(df[[\"feature1\",\"feature2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.348433       0.0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1  0.348433       0.0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2  0.348433       0.0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3  0.348433       0.0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4  0.348433       0.0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...    feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...     -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...     -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...     -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...      0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...     -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    g\n",
       "1    b\n",
       "2    g\n",
       "3    b\n",
       "4    g\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(\"label\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.348433       0.0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1  0.348433       0.0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2  0.348433       0.0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3  0.348433       0.0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4  0.348433       0.0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10    ...      feature25  feature26  feature27  \\\n",
       "0  -0.37708   1.00000    0.03760    ...        0.56811   -0.51171    0.41078   \n",
       "1  -0.93597   1.00000   -0.04549    ...       -0.20332   -0.26569   -0.20468   \n",
       "2  -0.12062   0.88965    0.01198    ...        0.57528   -0.40220    0.58984   \n",
       "3  -1.00000   0.00000    0.00000    ...        1.00000    0.90695    0.51613   \n",
       "4  -0.23255   0.77152   -0.16399    ...        0.03286   -0.65158    0.13290   \n",
       "\n",
       "   feature28  feature29  feature30  feature31  feature32  feature33  feature34  \n",
       "0   -0.46168    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300  \n",
       "1   -0.18401   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447  \n",
       "2   -0.22145    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238  \n",
       "3    1.00000    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000  \n",
       "4   -0.53206    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[:210]\n",
    "train_label = target.iloc[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.iloc[210:]\n",
    "test_label = target.iloc[210:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_label = le.fit_transform(train_label)\n",
    "test_label = le.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 34)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 34)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(10, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), \n",
    "                       input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(6,activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                350       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 423\n",
      "Trainable params: 423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 0s 197us/step - loss: 0.2758 - acc: 0.9286\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 0s 238us/step - loss: 0.2709 - acc: 0.9286\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 0s 153us/step - loss: 0.2663 - acc: 0.9286\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 0s 167us/step - loss: 0.2611 - acc: 0.9381\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 0s 158us/step - loss: 0.2566 - acc: 0.9381\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 0s 175us/step - loss: 0.2523 - acc: 0.9429\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 0s 203us/step - loss: 0.2481 - acc: 0.9429\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 0s 166us/step - loss: 0.2440 - acc: 0.9429\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 0s 157us/step - loss: 0.2406 - acc: 0.9429\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 0s 130us/step - loss: 0.2379 - acc: 0.9429\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 0s 189us/step - loss: 0.2331 - acc: 0.9429\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 0s 162us/step - loss: 0.2291 - acc: 0.9429\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 0s 177us/step - loss: 0.2266 - acc: 0.9429\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 0s 179us/step - loss: 0.2211 - acc: 0.9429\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 0s 186us/step - loss: 0.2169 - acc: 0.9476\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 0s 154us/step - loss: 0.2127 - acc: 0.9524\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 0s 215us/step - loss: 0.2078 - acc: 0.9571\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 0s 139us/step - loss: 0.2047 - acc: 0.9571\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 0s 168us/step - loss: 0.2009 - acc: 0.9571\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 0s 181us/step - loss: 0.1975 - acc: 0.9571\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 0s 193us/step - loss: 0.1952 - acc: 0.9524\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 0s 220us/step - loss: 0.1919 - acc: 0.9524\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 0s 172us/step - loss: 0.1893 - acc: 0.9571\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 0s 165us/step - loss: 0.1867 - acc: 0.9571\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 0s 213us/step - loss: 0.1838 - acc: 0.9571\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 0s 154us/step - loss: 0.1814 - acc: 0.9571\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 0s 222us/step - loss: 0.1787 - acc: 0.9571\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 0s 347us/step - loss: 0.1765 - acc: 0.9571\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 0s 216us/step - loss: 0.1741 - acc: 0.9571\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 0s 180us/step - loss: 0.1719 - acc: 0.9571\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 0s 170us/step - loss: 0.1696 - acc: 0.9571\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 0s 232us/step - loss: 0.1675 - acc: 0.9571\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 0s 188us/step - loss: 0.1657 - acc: 0.9571\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 0s 171us/step - loss: 0.1640 - acc: 0.9571\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 0s 174us/step - loss: 0.1620 - acc: 0.9571\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 0s 186us/step - loss: 0.1607 - acc: 0.9619\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 0s 242us/step - loss: 0.1591 - acc: 0.9619\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 0s 172us/step - loss: 0.1565 - acc: 0.9619\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 0s 175us/step - loss: 0.1549 - acc: 0.9619\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 0s 177us/step - loss: 0.1528 - acc: 0.9619\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 0s 218us/step - loss: 0.1515 - acc: 0.9619\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 0s 222us/step - loss: 0.1501 - acc: 0.9619\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 0s 226us/step - loss: 0.1482 - acc: 0.9619\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 0s 187us/step - loss: 0.1470 - acc: 0.9619\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 0s 155us/step - loss: 0.1452 - acc: 0.9619\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 0s 170us/step - loss: 0.1443 - acc: 0.9619\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 0s 157us/step - loss: 0.1443 - acc: 0.9619\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 0s 171us/step - loss: 0.1415 - acc: 0.9619\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 0s 185us/step - loss: 0.1399 - acc: 0.9619\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 0s 141us/step - loss: 0.1387 - acc: 0.9619\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 0s 182us/step - loss: 0.1375 - acc: 0.9619\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 0s 193us/step - loss: 0.1371 - acc: 0.9619\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 0s 162us/step - loss: 0.1351 - acc: 0.9619\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 0s 213us/step - loss: 0.1347 - acc: 0.9619\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 0s 229us/step - loss: 0.1326 - acc: 0.9619\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 0s 118us/step - loss: 0.1320 - acc: 0.9619\n",
      "Epoch 57/100\n",
      "210/210 [==============================] - 0s 253us/step - loss: 0.1306 - acc: 0.9619\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 0s 173us/step - loss: 0.1296 - acc: 0.9619\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 0s 179us/step - loss: 0.1283 - acc: 0.9619\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 0s 232us/step - loss: 0.1275 - acc: 0.9667\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 0s 229us/step - loss: 0.1264 - acc: 0.9667\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 0s 189us/step - loss: 0.1252 - acc: 0.9667\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 0s 182us/step - loss: 0.1249 - acc: 0.9619\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 0s 178us/step - loss: 0.1234 - acc: 0.9619\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 0s 174us/step - loss: 0.1224 - acc: 0.9667\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 0s 219us/step - loss: 0.1216 - acc: 0.9667\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 0s 114us/step - loss: 0.1209 - acc: 0.9714\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 0s 232us/step - loss: 0.1196 - acc: 0.9667\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 0s 243us/step - loss: 0.1189 - acc: 0.9667\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 0s 190us/step - loss: 0.1189 - acc: 0.9667\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 0s 218us/step - loss: 0.1171 - acc: 0.9619\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 0s 207us/step - loss: 0.1164 - acc: 0.9714\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 0s 179us/step - loss: 0.1156 - acc: 0.9714\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 0s 193us/step - loss: 0.1147 - acc: 0.9714\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 0s 175us/step - loss: 0.1138 - acc: 0.9714\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 0s 185us/step - loss: 0.1129 - acc: 0.9714\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 0s 234us/step - loss: 0.1122 - acc: 0.9667\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 0s 124us/step - loss: 0.1118 - acc: 0.9714\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 0s 231us/step - loss: 0.1100 - acc: 0.9714\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 0s 118us/step - loss: 0.1104 - acc: 0.9667\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 0s 176us/step - loss: 0.1090 - acc: 0.9667\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 0s 162us/step - loss: 0.1072 - acc: 0.9667\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 0s 203us/step - loss: 0.1060 - acc: 0.9667\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 0s 151us/step - loss: 0.1050 - acc: 0.9714\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 0s 136us/step - loss: 0.1045 - acc: 0.9667\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 0s 153us/step - loss: 0.1039 - acc: 0.9714\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 0s 153us/step - loss: 0.1033 - acc: 0.9762\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 0s 170us/step - loss: 0.1020 - acc: 0.9714\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 0s 161us/step - loss: 0.1010 - acc: 0.9714\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 0s 162us/step - loss: 0.1001 - acc: 0.9714\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 0s 164us/step - loss: 0.0988 - acc: 0.9762\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 0s 164us/step - loss: 0.0981 - acc: 0.9714\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 0s 158us/step - loss: 0.0984 - acc: 0.9714\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 0s 154us/step - loss: 0.0968 - acc: 0.9762\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 0s 210us/step - loss: 0.0958 - acc: 0.9762\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 0s 155us/step - loss: 0.0951 - acc: 0.9762\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 0s 159us/step - loss: 0.0944 - acc: 0.9762\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 0s 166us/step - loss: 0.0934 - acc: 0.9762\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 0s 151us/step - loss: 0.0929 - acc: 0.9762\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 0s 145us/step - loss: 0.0920 - acc: 0.9762\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(train_data, train_label, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 629us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09312877825177307, 0.9787234046780471]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
