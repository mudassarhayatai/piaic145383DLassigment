{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"ionosphere_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...    feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...     -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...     -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...     -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...      0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...     -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      "feature1     351 non-null int64\n",
      "feature2     351 non-null int64\n",
      "feature3     351 non-null float64\n",
      "feature4     351 non-null float64\n",
      "feature5     351 non-null float64\n",
      "feature6     351 non-null float64\n",
      "feature7     351 non-null float64\n",
      "feature8     351 non-null float64\n",
      "feature9     351 non-null float64\n",
      "feature10    351 non-null float64\n",
      "feature11    351 non-null float64\n",
      "feature12    351 non-null float64\n",
      "feature13    351 non-null float64\n",
      "feature14    351 non-null float64\n",
      "feature15    351 non-null float64\n",
      "feature16    351 non-null float64\n",
      "feature17    351 non-null float64\n",
      "feature18    351 non-null float64\n",
      "feature19    351 non-null float64\n",
      "feature20    351 non-null float64\n",
      "feature21    351 non-null float64\n",
      "feature22    351 non-null float64\n",
      "feature23    351 non-null float64\n",
      "feature24    351 non-null float64\n",
      "feature25    351 non-null float64\n",
      "feature26    351 non-null float64\n",
      "feature27    351 non-null float64\n",
      "feature28    351 non-null float64\n",
      "feature29    351 non-null float64\n",
      "feature30    351 non-null float64\n",
      "feature31    351 non-null float64\n",
      "feature32    351 non-null float64\n",
      "feature33    351 non-null float64\n",
      "feature34    351 non-null float64\n",
      "label        351 non-null object\n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "se = StandardScaler()\n",
    "df[[\"feature1\",\"feature2\"]] = se.fit_transform(df[[\"feature1\",\"feature2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.348433       0.0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1  0.348433       0.0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2  0.348433       0.0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3  0.348433       0.0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4  0.348433       0.0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...    feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...     -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...     -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...     -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...      0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...     -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    g\n",
       "1    b\n",
       "2    g\n",
       "3    b\n",
       "4    g\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(\"label\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56811</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.20332</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57528</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  0.348433       0.0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1  0.348433       0.0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2  0.348433       0.0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3  0.348433       0.0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4  0.348433       0.0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10    ...      feature25  feature26  feature27  \\\n",
       "0  -0.37708   1.00000    0.03760    ...        0.56811   -0.51171    0.41078   \n",
       "1  -0.93597   1.00000   -0.04549    ...       -0.20332   -0.26569   -0.20468   \n",
       "2  -0.12062   0.88965    0.01198    ...        0.57528   -0.40220    0.58984   \n",
       "3  -1.00000   0.00000    0.00000    ...        1.00000    0.90695    0.51613   \n",
       "4  -0.23255   0.77152   -0.16399    ...        0.03286   -0.65158    0.13290   \n",
       "\n",
       "   feature28  feature29  feature30  feature31  feature32  feature33  feature34  \n",
       "0   -0.46168    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300  \n",
       "1   -0.18401   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447  \n",
       "2   -0.22145    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238  \n",
       "3    1.00000    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000  \n",
       "4   -0.53206    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[:210]\n",
    "train_label = target.iloc[:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.iloc[210:]\n",
    "test_label = target.iloc[210:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_label = le.fit_transform(train_label)\n",
    "test_label = le.fit_transform(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 34)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mudassir/anaconda3/envs/snakes/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(10, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), \n",
    "                       input_shape=(train_data.shape[1],)))\n",
    "model.add(layers.Dense(6,activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                350       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 423\n",
      "Trainable params: 423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6848 - acc: 0.5190\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 0s 140us/step - loss: 0.6742 - acc: 0.5952\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 0s 168us/step - loss: 0.6655 - acc: 0.6571\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 0s 151us/step - loss: 0.6582 - acc: 0.6714\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 0s 174us/step - loss: 0.6506 - acc: 0.7095\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 0s 165us/step - loss: 0.6431 - acc: 0.7333\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 0s 154us/step - loss: 0.6362 - acc: 0.7524\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 0s 226us/step - loss: 0.6284 - acc: 0.7571\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 0s 287us/step - loss: 0.6208 - acc: 0.7714\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 0s 197us/step - loss: 0.6126 - acc: 0.7714\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 0s 181us/step - loss: 0.6052 - acc: 0.7952\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 0s 178us/step - loss: 0.5974 - acc: 0.7905\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 0s 202us/step - loss: 0.5899 - acc: 0.8000\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 0s 184us/step - loss: 0.5822 - acc: 0.8000\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 0s 179us/step - loss: 0.5743 - acc: 0.8190\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 0s 210us/step - loss: 0.5666 - acc: 0.8238\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 0s 136us/step - loss: 0.5587 - acc: 0.8286\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 0s 215us/step - loss: 0.5505 - acc: 0.8381\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 0s 191us/step - loss: 0.5430 - acc: 0.8381\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 0s 215us/step - loss: 0.5349 - acc: 0.8476\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 0s 180us/step - loss: 0.5278 - acc: 0.8476\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 0s 178us/step - loss: 0.5202 - acc: 0.8476\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 0s 208us/step - loss: 0.5128 - acc: 0.8571\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 0s 179us/step - loss: 0.5050 - acc: 0.8762\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 0s 190us/step - loss: 0.4972 - acc: 0.8762\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 0s 171us/step - loss: 0.4896 - acc: 0.8762\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 0s 220us/step - loss: 0.4822 - acc: 0.8857\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 0s 177us/step - loss: 0.4754 - acc: 0.8952\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 0s 173us/step - loss: 0.4689 - acc: 0.9048\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 0s 211us/step - loss: 0.4622 - acc: 0.9095\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 0s 166us/step - loss: 0.4565 - acc: 0.9143\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 0s 184us/step - loss: 0.4514 - acc: 0.9143\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 0s 177us/step - loss: 0.4459 - acc: 0.9143\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 0s 169us/step - loss: 0.4412 - acc: 0.9095\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 0s 206us/step - loss: 0.4365 - acc: 0.9095\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 0s 148us/step - loss: 0.4317 - acc: 0.9143\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 0s 181us/step - loss: 0.4273 - acc: 0.9143\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 0s 186us/step - loss: 0.4231 - acc: 0.9143\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 0s 209us/step - loss: 0.4190 - acc: 0.9143\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 0s 175us/step - loss: 0.4150 - acc: 0.9143\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 0s 181us/step - loss: 0.4112 - acc: 0.9143\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 0s 245us/step - loss: 0.4078 - acc: 0.9190\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 0s 208us/step - loss: 0.4041 - acc: 0.9190\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 0s 165us/step - loss: 0.4007 - acc: 0.9190\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 0s 189us/step - loss: 0.3978 - acc: 0.9190\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 0s 154us/step - loss: 0.3942 - acc: 0.9190\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 0s 148us/step - loss: 0.3909 - acc: 0.9190\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 0s 202us/step - loss: 0.3879 - acc: 0.9190\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 0s 172us/step - loss: 0.3848 - acc: 0.9190\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 0s 171us/step - loss: 0.3817 - acc: 0.9190\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 0s 199us/step - loss: 0.3788 - acc: 0.9238\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 0s 168us/step - loss: 0.3760 - acc: 0.9333\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 0s 213us/step - loss: 0.3728 - acc: 0.9333\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 0s 201us/step - loss: 0.3702 - acc: 0.9333\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 0s 156us/step - loss: 0.3674 - acc: 0.9333\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 0s 183us/step - loss: 0.3647 - acc: 0.9381\n",
      "Epoch 57/100\n",
      "210/210 [==============================] - 0s 193us/step - loss: 0.3622 - acc: 0.9381\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 0s 157us/step - loss: 0.3596 - acc: 0.9333\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 0s 229us/step - loss: 0.3569 - acc: 0.9333\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 0s 281us/step - loss: 0.3544 - acc: 0.9381\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 0s 220us/step - loss: 0.3518 - acc: 0.9381\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 0s 305us/step - loss: 0.3494 - acc: 0.9381\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 0s 250us/step - loss: 0.3469 - acc: 0.9429\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 0s 156us/step - loss: 0.3445 - acc: 0.9381\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 0s 290us/step - loss: 0.3423 - acc: 0.9429\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 0s 379us/step - loss: 0.3396 - acc: 0.9429\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 0s 391us/step - loss: 0.3376 - acc: 0.9524\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 0s 244us/step - loss: 0.3352 - acc: 0.9571\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 0s 167us/step - loss: 0.3327 - acc: 0.9571\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 0s 226us/step - loss: 0.3308 - acc: 0.9571\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 0s 165us/step - loss: 0.3287 - acc: 0.9571\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 0s 220us/step - loss: 0.3262 - acc: 0.9571\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 0s 254us/step - loss: 0.3242 - acc: 0.9571\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 0s 228us/step - loss: 0.3217 - acc: 0.9571\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 0s 200us/step - loss: 0.3198 - acc: 0.9571\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 0s 305us/step - loss: 0.3174 - acc: 0.9619\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 0s 141us/step - loss: 0.3154 - acc: 0.9619\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 0s 152us/step - loss: 0.3131 - acc: 0.9619\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 0s 181us/step - loss: 0.3112 - acc: 0.9619\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 0s 118us/step - loss: 0.3090 - acc: 0.9714\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 0s 167us/step - loss: 0.3069 - acc: 0.9714\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 0s 177us/step - loss: 0.3046 - acc: 0.9762\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 0s 181us/step - loss: 0.3026 - acc: 0.9714\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 0s 185us/step - loss: 0.3007 - acc: 0.9714\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 0s 145us/step - loss: 0.2986 - acc: 0.9762\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 0s 179us/step - loss: 0.2965 - acc: 0.9762\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 0s 161us/step - loss: 0.2945 - acc: 0.9762\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 0s 173us/step - loss: 0.2925 - acc: 0.9762\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 0s 147us/step - loss: 0.2912 - acc: 0.9714\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 0s 164us/step - loss: 0.2885 - acc: 0.9762\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 0s 178us/step - loss: 0.2870 - acc: 0.9762\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 0s 233us/step - loss: 0.2855 - acc: 0.9762\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 0s 151us/step - loss: 0.2832 - acc: 0.9762\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 0s 213us/step - loss: 0.2811 - acc: 0.9810\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 0s 215us/step - loss: 0.2794 - acc: 0.9810\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 0s 164us/step - loss: 0.2774 - acc: 0.9810\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 0s 243us/step - loss: 0.2757 - acc: 0.9810\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 0s 191us/step - loss: 0.2738 - acc: 0.9810\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 0s 274us/step - loss: 0.2722 - acc: 0.9810\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 0s 238us/step - loss: 0.2704 - acc: 0.9810\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(train_data, train_label, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 513us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4058400090281845, 0.9716312056737588]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dic = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_Values = history_dic[\"loss\"]\n",
    "val_loss_values = history_dic[\"loss\"]\n",
    "epochs = range(1, len(loss_Values) + 1)\n",
    "plt.plot(epochs, loss_Values, 'bo', label=\"training loss\")\n",
    "plt.plot(epochs, val_loss_values,'b', label=\"validation loss\")\n",
    "plt.title(\"training and validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
